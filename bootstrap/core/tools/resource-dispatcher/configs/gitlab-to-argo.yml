repositories:
  - name: automation-repo
    url: https://github.com/rht-labs/labs-sre-automation.git
    ref: v1.0.29-2

tasks:
  - name: gitlab-to-argo
    description: Ensures that all repositories in a GitLab group are being watched by an Argo CD instance
    triggers:
      - type: scheduled
        every: 10 minutes
      - type: webhook
        route: /gitlab_to_argo
    steps:
      - plugin: ansible
        repository: automation-repo
        path: gitlab-to-argo
        params:
          playbook_path: site.yml
          inventory_path: inventory
          extra_vars:
            gitlab_base_url: https://{{ ENV_GITLAB_BASE_URL }}
            gitlab_group: {{ ENV_GITLAB_GROUP | trim }}
            gitlab_private_token: {{ ENV_GITLAB_PRIVATE_TOKEN | trim }}
            destination_namespace: {{ ENV_BABYLON_NAMESPACE }}
            chart_path: "ocp-init/"
            syncPolicy: False
      - plugin: script
        description: Remove Argo app definitions for projects which are not ready to be launched
        repository: automation-repo
        path: gitlab-to-argo/output
        params:
          packages:
            - python-gitlab
          script: |
            from datetime import datetime
            import json
            import os
            import gitlab
            import dateutil.parser

            print("Checking projects from https://{{ ENV_GITLAB_BASE_URL }}" )
            g = gitlab.Gitlab(
              "https://{{ ENV_GITLAB_BASE_URL }}" ,
              private_token="{{ ENV_GITLAB_PRIVATE_TOKEN | trim }}"
            )

            def should_process_project(project):
              try:
                repository_tree = project.repository_tree(all=True)
              except Exception as err:
                print("Failed to walk repository file tree, are there any files in this repository?")              
                print(err)
                return False
              engagement_file = [f for f in repository_tree if f["path"] == 'engagement.json']
              if not len(engagement_file) == 1:
                # Engagement file doesn't exist
                return False
              engagement = json.loads(project.files.get('engagement.json', "master").decode())
              print("Checking Engagement: %s - %s"
                    %(engagement.get('customer_name', 'Undefined'),
                      engagement.get('project_name', 'Undefined')))
              if not ("launch" in engagement and "launched_date_time" in engagement["launch"]):
                # Engagement file doesn't have the correct launch data in it
                return False
              if "archive_date" in engagement:
                try:
                  archive_date_ts = dateutil.parser.parse(engagement["archive_date"]).timestamp()
                except ValueError:
                  print("Could not parse archive date: %s" %engagement["archive_date"])
                  return False
                now_ts = datetime.utcnow().timestamp()
                if now_ts > archive_date_ts:
                  # We're past the engagement archive_date and should not process
                  return False
              if (not "hosting_environments" in engagement or
                  len(engagement["hosting_environments"]) == 0 or 
                  not "ocp_cloud_provider_name" in engagement["hosting_environments"][0] or 
                  engagement["hosting_environments"][0]["ocp_cloud_provider_name"] != "ec2"):
                return False
              return True

            def do_not_process(file):
              print(f"Not processing {file}")
              os.remove(file)

            files = [f for f in os.listdir(".")]
            for file in files:
              project_id = file.partition(".")[0] # The project ID is the filename before ".yml"
              project = g.projects.get(project_id, lazy=False)
              if not should_process_project(project):
                do_not_process(file)
      - plugin: kubernetes
        repository: automation-repo
        path: gitlab-to-argo/output
        params:
          mode: in-cluster
          apply_objects:
            from_dir: "."
            namespace: "openshift-gitops"
